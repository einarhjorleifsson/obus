# obus

{obus} is a temporary experimental package used to explore various
DATRAS data connections and wrapper functions to make life a little
easier for everyday DATRAS data user to access the data. Once that is
settled the aim is to provide downstream convenience functions, again to
make coding life a little bit more enjoyable.

Some of this may potentially be taken up in a more offical package
maintained by ICES datacenter.

## Installation

You can install the development version of imbus from
[GitHub](https://github.com/einarhjorleifsson/obus) with:

``` r
# install.packages("pak")
#pak::pak("einarhjorleifsson/obus")
```

## Different ways to skin a cat

We currently have three way to skin the cat, excluding here the old
faithful icesDatras::icesDATRAS. Here the focus is on accessing the full
HL-type data in one function call:

1.  Download via the new API

- data.table:
- arrow:

2.  Read parquet files directly from “the cloud”

- parquet:

The first two approaches are the same when it comes to downloading the
zip-file and unzipping the csv-file. The difference is how the csv-file
is read.

The second approach reads parquet file stored on a spartan url-server at
a temporary site. Cloud based server is being explored by ICES
datacenter, that may though be a bit of an overkill give that the DATRAS
data is not really big.

``` r
library(obus)
library(tidyverse)
#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
#> ✔ dplyr     1.1.4     ✔ readr     2.1.6
#> ✔ forcats   1.0.1     ✔ stringr   1.6.0
#> ✔ ggplot2   4.0.1     ✔ tibble    3.3.1
#> ✔ lubridate 1.9.4     ✔ tidyr     1.3.2
#> ✔ purrr     1.2.0     
#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
#> ✖ dplyr::filter() masks stats::filter()
#> ✖ dplyr::lag()    masks stats::lag()
#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
library(tictoc)
surveys <- c("BITS", "BTS", "BTS-GSA17", "BTS-VIII",
             "Can-Mar",   "DWS",       "DYFS",      "EVHOE",
             "FR-CGFS",   "FR-WCGFS",  "IE-IAMS",   "IE-IGFS",
             "IS-IDPS",   "NIGFS",     "NL-BSAS",   "NS-IBTS",
             "NS-IDPS",   "NSSS",      "PT-IBTS",   "ROCKALL",
             "SCOROC",    "SCOWCGFS",  "SE-SOUND",  "SNS",
             "SP-ARSA",   "SP-NORTH",  "SP-PORC",   "SWC-IBTS")

# Use the new API, read downloaded file using data.table::fread
tic()
hl_data.table <- 
  map2("HL", surveys, dr_read_datras, how = "data.table") |> 
  bind_rows()
toc()
#> 75.083 sec elapsed
# Use the new API, read downloaded file using arrow::read_csv_arrow
tic()
hl_arrow <- 
  map2("HL", surveys, dr_read_datras, how = "arrow") |> 
  bind_rows()
toc()
#> 74.384 sec elapsed
# Read parquet files from url
tic()
hl_parquet <- dr_read_datras("HL", how = "parquet")
toc()
#> 12.935 sec elapsed
```

## Another way of thinking

In all cases above we are importing the full sweep of the DATRAS data
into R. This may be a bit of an overkill, given that R …

There is another way:

- Connect to web hosted parquet files
- …

``` r
hh <- dr_con("HH")
hl <- dr_con("HL")
ca <- dr_con("CA")
```

## A little peek

``` r
library(tidyverse)
hl |> glimpse()
#> Rows: ??
#> Columns: 7
#> Database: DuckDB 1.4.3 [unknown@Linux 5.10.0-33-amd64:R 4.4.1/:memory:]
#> $ .id              <chr> "BITS:1991:1:DE:06S1:H20:48:43", "BITS:1991:1:DE:06S1…
#> $ latin            <chr> "Pleuronectes platessa", "Pleuronectes platessa", "Po…
#> $ length_cm        <dbl> 24.0, 25.0, 24.0, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5,…
#> $ SpeciesSex       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#> $ DevelopmentStage <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#> $ n                <dbl> 1.0, 2.0, 1.0, 4.5, 4.5, 14.0, 28.5, 9.5, 9.5, 23.5, …
#> $ cpue             <dbl> 2, 4, 2, 9, 9, 28, 57, 19, 19, 47, 38, 9, 9, 376, 376…
```

## A little exploration

``` r
library(santoku)
#> 
#> Attaching package: 'santoku'
#> The following object is masked from 'package:tidyr':
#> 
#>     chop
# Grid resolution
dx <- 1
dy <- dx / 2
# Limit analysis to certain time and space
hh |> 
  filter(Year %in% 2001:2010,
         between(ShootLongitude, -20, 25),
         between(ShootLatitude, -Inf, 65)) |> 
  # assign coordinates to grid
  mutate(lon = ShootLongitude%/%dx * dx + dx/2,
         lat = ShootLatitude%/%dy * dy + dy/2) |> 
  left_join(hl |> 
              select(.id, latin),
           by = join_by(.id)) |>
  # analyse by grid
  group_by(lon, lat) |> 
  summarise(n_taxa = n_distinct(latin),
            .groups = "drop") |> 
  # load data into R memory because santoku::chop not in duckdb lingo
  #  chop is also nicer than cut - keeps things more orderly
  collect() |> 
  mutate(n_taxa = chop(n_taxa, breaks = c(0, 25, 50, 75, 100, 125, 150, 200))) |> 
  ggplot(aes(lon, lat, fill = n_taxa)) +
  geom_tile() +
  scale_fill_viridis_d(option = "inferno", direction = -1) +
  coord_quickmap() +
  labs(x = NULL, y = NULL, fill = "Number of\ndistinct taxa",
       caption = "DATRAS 2001-2010, core area: Number of distinct taxa reported per rectangle")
```

![](reference/figures/README-demo-1.png)

# Package index

## All functions

- [`dr_add_date()`](https://einarhjorleifsson.github.io/obus/reference/dr_add_date.md)
  :

  Calculate date based on `Year`, `Month`, and `Day`.

- [`dr_add_id()`](https://einarhjorleifsson.github.io/obus/reference/dr_add_id.md)
  : Generate a unique haul id

- [`dr_add_length_cm()`](https://einarhjorleifsson.github.io/obus/reference/dr_add_length_cm.md)
  :

  Add a standardized `length_cm` column to the input table

- [`dr_add_n_and_cpue()`](https://einarhjorleifsson.github.io/obus/reference/dr_add_n_and_cpue.md)
  : Numbers caught and the CPUE in each length class

- [`dr_add_starttime()`](https://einarhjorleifsson.github.io/obus/reference/dr_add_starttime.md)
  :

  Calculate timestamp based on `Year`, `Month`, `Day`, and
  `StartTime`/`TimeShot`.

- [`dr_catch_weight()`](https://einarhjorleifsson.github.io/obus/reference/dr_catch_weight.md)
  : Get catch weights

- [`dr_coastline`](https://einarhjorleifsson.github.io/obus/reference/dr_coastline.md)
  : A valid aphia id - latin name lookup

- [`dr_coltypes`](https://einarhjorleifsson.github.io/obus/reference/dr_coltypes.md)
  : Datras variable types

- [`dr_con()`](https://einarhjorleifsson.github.io/obus/reference/dr_con.md)
  : Create a DuckDB connection to a DATRAS tables

- [`dr_con_latin()`](https://einarhjorleifsson.github.io/obus/reference/dr_con_latin.md)
  : Connect to the Species WoRMS Dataset

- [`dr_download_data_latin()`](https://einarhjorleifsson.github.io/obus/reference/dr_download_data_latin.md)
  : Download DATRAS latin tables

- [`dr_get_ca()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_ca.md)
  : Retrieve DATRAS Age (CA) Table

- [`dr_get_data_latin()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_data_latin.md)
  : Get DATRAS tables with latin names

- [`dr_get_datras()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_datras.md)
  : Retrieve DATRAS exchange table

- [`dr_get_datras_download()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_datras_download.md)
  : Download DATRAS tables

- [`dr_get_fl()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_fl.md)
  : Retrieve DATRAS Flex (FL) Table

- [`dr_get_hh()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_hh.md)
  : Retrieve DATRAS Station (HH) Table

- [`dr_get_hl()`](https://einarhjorleifsson.github.io/obus/reference/dr_get_hl.md)
  : Retrieve DATRAS Length (HL) Table

- [`dr_latin_aphia`](https://einarhjorleifsson.github.io/obus/reference/dr_latin_aphia.md)
  : Coastline covering majority of DATRAS data

- [`dr_read_datras()`](https://einarhjorleifsson.github.io/obus/reference/dr_read_datras.md)
  : Download, extract, and import DATRAS Data

- [`dr_settypes()`](https://einarhjorleifsson.github.io/obus/reference/dr_settypes.md)
  : Set variable types

# Articles

### All vignettes

- [On
  meanings](https://einarhjorleifsson.github.io/obus/articles/on_meanings.md):
- [Package
  overview](https://einarhjorleifsson.github.io/obus/articles/overview.md):
